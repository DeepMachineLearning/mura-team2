import torch.utils.data as data
import csv
from PIL import Image as PImage
import torchvision.transforms as transforms
import numpy as np


class CD_Dataset(data.Dataset):
    def __init__(self, src, path_csv, label_csv, transform=None):
        with open(path_csv, 'r') as f:
            path_reader = csv.reader(f)
            p_list = list(path_reader)
           
        with open(label_csv, 'r') as f:
            label_reader = csv.reader(f)
            l_list = list(label_reader)

        self.labels = []
        self.pathes = []

        for i in range(len(p_list)):
            self.pathes.append(*p_list[i])
            self.pathes[i] = src + self.pathes[i]
            #print(self.pathes[i])
        for i in range(len(l_list)):
            self.labels.append(*l_list[i][1])
    
        self.transform = transform


    def __getitem__(self, idx):
        img_path = self.pathes[idx]
        category = self.labels[idx]
        image = PImage.open(img_path).convert('RGB')
        
        if self.transform:
            image = self.transform(image)
    
        return image, category

    def __len__(self):
        return len(self.labels)

img_path = '/home/ubuntu/MURA/MURA-v1.1/train_image_paths.csv'
label_path = '/home/ubuntu/MURA/MURA-v1.1/train_labeled_studies.csv'

src = '/home/ubuntu/MURA/'


transform_image = transforms.Compose([
        transforms.Resize ([256, 256]),
        transforms.ToTensor(),
        transforms.Normalize((0.5,0.5,0.5), (0.5,0.5,0.5))
])

MURA_dataset = CD_Dataset(src,img_path, label_path,transform=transform_image)

MURA_loader = data.DataLoader(MURA_dataset, batch_size=2)

image,label = next(iter(MURA_loader))

print(image)
print(label)
